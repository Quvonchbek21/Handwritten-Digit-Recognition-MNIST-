{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision gradio matplotlib"
      ],
      "metadata": {
        "id": "duU--ftw8tmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps"
      ],
      "metadata": {
        "id": "9iY00dqM-eBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMNISTCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        # Corrected input size to the first fully connected layer\n",
        "        self.fc1 = nn.Linear(64*14*14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ],
      "metadata": {
        "id": "YrvHZhq2-iCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "KyeEevbr_8Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleMNISTCNN().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZhywNDLI_-xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "print_interval = 5\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    correct, total, loss_sum = 0, 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    # faqat har 10 epochda natijani chiqaramiz\n",
        "    if epoch % print_interval == 0 or epoch == 1:\n",
        "        avg_loss = loss_sum / len(train_loader)\n",
        "        acc = correct / total * 100\n",
        "        print(f\"ðŸ“˜ Epoch {epoch}/{num_epochs}: loss={avg_loss:.4f}, acc={acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdQdz5oNAF-l",
        "outputId": "25631866-13a5-4c34-98dc-309b3cf9cf4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Epoch 1/20: loss=0.0029, acc=99.92%\n",
            "ðŸ“˜ Epoch 5/20: loss=0.0033, acc=99.91%\n",
            "ðŸ“˜ Epoch 10/20: loss=0.0020, acc=99.94%\n",
            "ðŸ“˜ Epoch 15/20: loss=0.0020, acc=99.94%\n",
            "ðŸ“˜ Epoch 20/20: loss=0.0021, acc=99.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
      ],
      "metadata": {
        "id": "l-DQn5xbZ6zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Bashorat uchun yuklash ---\n",
        "model = SimpleMNISTCNN()\n",
        "model.load_state_dict(torch.load(\"mnist_cnn.pth\", map_location=\"cpu\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRxRdYfcZAy6",
        "outputId": "acd76603-5a75-400f-cfef-461a25f0e571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleMNISTCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import traceback\n",
        "def predict_with_debug(img):\n",
        "    try:\n",
        "        if img is None:\n",
        "            raise ValueError(\"Rasm topilmadi â€” iltimos, chizing va Submit bosing.\")\n",
        "\n",
        "        # --- Sketchpad formatini tozalash ---\n",
        "        if isinstance(img, dict):\n",
        "            if \"image\" in img and img[\"image\"] is not None:\n",
        "                img = img[\"image\"]\n",
        "            elif \"layers\" in img and len(img[\"layers\"]) > 0:\n",
        "                img = img[\"layers\"][-1]\n",
        "            else:\n",
        "                raise ValueError(\"Sketchpad rasmni yubormadi (boâ€˜sh).\")\n",
        "\n",
        "        # --- Numpy array -> PIL Image ---\n",
        "        if isinstance(img, np.ndarray):\n",
        "            arr = img\n",
        "            # RGB yoki RGBA formatlarni kulrangga aylantirish\n",
        "            if arr.ndim == 3:\n",
        "                if arr.shape[2] == 4:\n",
        "                    arr = arr[:, :, 3]  # alpha kanal\n",
        "                else:\n",
        "                    arr = arr[:, :, 0]  # 1-kanal\n",
        "            pil = Image.fromarray(arr.astype(np.uint8)).convert(\"L\")\n",
        "        else:\n",
        "            pil = img.convert(\"L\")\n",
        "\n",
        "        # --- 28x28 ga oâ€˜lchamlashtirish ---\n",
        "        pil = pil.resize((28, 28), Image.LANCZOS)\n",
        "\n",
        "        # --- Tensor tayyorlash ---\n",
        "        arr = np.array(pil).astype(np.float32) / 255.0\n",
        "        arr = (arr - 0.1307) / 0.3081  # MNIST normalizatsiyasi\n",
        "        x = torch.tensor(arr, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # --- Model bashorati ---\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "        return {str(i): float(probs[i]) for i in range(10)}, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(\"==== PREDICT ERROR TRACEBACK ====\\n\", traceback.format_exc())\n",
        "        return {str(i): 0.0 for i in range(10)}, f\"Error: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "# ðŸ”¹ Gradio interfeysini yaratish\n",
        "input_sketchpad = gr.Sketchpad(label=\"Raqam chizing\")\n",
        "output_label = gr.Label(label=\"Bashorat\")\n",
        "output_text = gr.Textbox(label=\"Xatolar\")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_with_debug,\n",
        "    inputs=input_sketchpad,\n",
        "    outputs=[output_label, output_text],\n",
        "    live=True\n",
        ")\n",
        "\n",
        "# ðŸ”¹ Gradio ilovasini ishga tushirish\n",
        "demo.launch(share=True, debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "TJgEmmXRNUru",
        "outputId": "d5440f19-6576-4708-ac59-ea2dbb9c88a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://dbbb2fd73b765ac399.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://dbbb2fd73b765ac399.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}