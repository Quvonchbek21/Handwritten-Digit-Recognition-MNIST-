{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iY00dqM-eBw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrvHZhq2-iCS"
      },
      "outputs": [],
      "source": [
        "class SimpleMNISTCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        # Corrected input size to the first fully connected layer\n",
        "        self.fc1 = nn.Linear(64*14*14, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyeEevbr_8Yl"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhywNDLI_-xq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = SimpleMNISTCNN().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdQdz5oNAF-l",
        "outputId": "6cfe3f2c-d331-488b-bf58-9935729567da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“˜ Epoch 1/5: loss=0.1656, acc=94.93%\n",
            "ðŸ“˜ Epoch 2/5: loss=0.0559, acc=98.28%\n",
            "ðŸ“˜ Epoch 3/5: loss=0.0383, acc=98.78%\n",
            "ðŸ“˜ Epoch 4/5: loss=0.0298, acc=99.03%\n",
            "ðŸ“˜ Epoch 5/5: loss=0.0253, acc=99.18%\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "print_interval = 1\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model.train()\n",
        "    correct, total, loss_sum = 0, 0, 0\n",
        "\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "        correct += (out.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "\n",
        "    if epoch % print_interval == 0 or epoch == 1:\n",
        "        avg_loss = loss_sum / len(train_loader)\n",
        "        acc = correct / total * 100\n",
        "        print(f\"ðŸ“˜ Epoch {epoch}/{num_epochs}: loss={avg_loss:.4f}, acc={acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-DQn5xbZ6zP"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRxRdYfcZAy6",
        "outputId": "36b45454-1c53-4a32-a440-25e153492247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleMNISTCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=12544, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = SimpleMNISTCNN()\n",
        "model.load_state_dict(torch.load(\"mnist_cnn.pth\", map_location=\"cpu\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "TJgEmmXRNUru",
        "outputId": "c801a0a8-7a9e-4c91-a490-f0c904d6e102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://6155c23bf8eb79e619.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6155c23bf8eb79e619.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import traceback\n",
        "def predict_with_debug(img):\n",
        "    try:\n",
        "        if img is None:\n",
        "            raise ValueError(\"Rasm topilmadi â€” iltimos, chizing va Submit bosing.\")\n",
        "\n",
        "\n",
        "        if isinstance(img, dict):\n",
        "            if \"image\" in img and img[\"image\"] is not None:\n",
        "                img = img[\"image\"]\n",
        "            elif \"layers\" in img and len(img[\"layers\"]) > 0:\n",
        "                img = img[\"layers\"][-1]\n",
        "            else:\n",
        "                raise ValueError(\"Sketchpad rasmni yubormadi (boâ€˜sh).\")\n",
        "\n",
        "\n",
        "        if isinstance(img, np.ndarray):\n",
        "            arr = img\n",
        "\n",
        "            if arr.ndim == 3:\n",
        "                if arr.shape[2] == 4:\n",
        "                    arr = arr[:, :, 3]\n",
        "                else:\n",
        "                    arr = arr[:, :, 0]\n",
        "            pil = Image.fromarray(arr.astype(np.uint8)).convert(\"L\")\n",
        "        else:\n",
        "            pil = img.convert(\"L\")\n",
        "\n",
        "\n",
        "        pil = pil.resize((28, 28), Image.LANCZOS)\n",
        "\n",
        "\n",
        "        arr = np.array(pil).astype(np.float32) / 255.0\n",
        "        arr = (arr - 0.1307) / 0.3081  # MNIST normalizatsiyasi\n",
        "        x = torch.tensor(arr, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            probs = F.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "\n",
        "        return {str(i): float(probs[i]) for i in range(10)}, \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(\"==== PREDICT ERROR TRACEBACK ====\\n\", traceback.format_exc())\n",
        "        return {str(i): 0.0 for i in range(10)}, f\"Error: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_sketchpad = gr.Sketchpad(label=\"Raqam chizing\")\n",
        "output_label = gr.Label(label=\"Bashorat\")\n",
        "output_text = gr.Textbox(label=\"Xatolar\")\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_with_debug,\n",
        "    inputs=input_sketchpad,\n",
        "    outputs=[output_label, output_text],\n",
        "    live=True\n",
        ")\n",
        "\n",
        "\n",
        "demo.launch(share=True, debug=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}